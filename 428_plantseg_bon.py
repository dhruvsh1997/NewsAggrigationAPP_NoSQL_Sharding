# -*- coding: utf-8 -*-
"""428-plantseg-bon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11trp5xIMasq6yLWvsiN-NT0uhmEa4GKN
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import tensorflow as tf

from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.layers import Conv2D, UpSampling2D, BatchNormalization, Activation, MaxPool2D,MaxPooling2D ,Conv2DTranspose, Concatenate, Input, Dropout
from tensorflow.keras.models import Model

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Activation, concatenate, UpSampling2D, Add, Lambda
from tensorflow.keras.models import Model
from tensorflow.keras.layers import DepthwiseConv2D
import tensorflow as tf

# Define the weighted sum fusion function
def weighted_feature_fusion(features, filters, name):
    transformed_features = [Conv2D(filters, kernel_size=(1, 1), padding="same")(feature) for feature in features]
    w = tf.Variable(initial_value=tf.ones((len(features),), dtype=tf.float32), trainable=True, name=f"weights_{name}")
    w = tf.nn.relu(w)
    weight_sum = tf.reduce_sum(w) + 1e-4
    weights = w / weight_sum
    fused_feature = Add()([weights[i] * transformed_features[i] for i in range(len(features))])
    return fused_feature

# Define the Depthwise Separable Convolution used in BiFPN
def depthwise_separable_conv(x, filters, kernel_size, strides=1, padding="same"):
    x = DepthwiseConv2D(kernel_size=kernel_size, strides=strides, padding=padding)(x)
    x = Conv2D(filters, kernel_size=(1, 1), padding="same")(x)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x

# Define the BiFPN block
def BiFPNBlock(features, filters):
    P3, P4, P5, P6, P7 = features

    # Top-down pathway
    P6_td = weighted_feature_fusion([P6, UpSampling2D()(P7)], filters, name="P6_td")
    P6_td = depthwise_separable_conv(P6_td, filters, kernel_size=3)

    P5_td = weighted_feature_fusion([P5, UpSampling2D()(P6_td)], filters, name="P5_td")
    P5_td = depthwise_separable_conv(P5_td, filters, kernel_size=3)

    P4_td = weighted_feature_fusion([P4, UpSampling2D()(P5_td)], filters, name="P4_td")
    P4_td = depthwise_separable_conv(P4_td, filters, kernel_size=3)

    P3_td = weighted_feature_fusion([P3, UpSampling2D()(P4_td)], filters, name="P3_td")
    P3_td = depthwise_separable_conv(P3_td, filters, kernel_size=3)

    # Bottom-up pathway
    P4_out = weighted_feature_fusion([P4, P4_td, MaxPooling2D(pool_size=(2, 2))(P3_td)], filters, name="P4_out")
    P4_out = depthwise_separable_conv(P4_out, filters, kernel_size=3)

    P5_out = weighted_feature_fusion([P5, P5_td, MaxPooling2D(pool_size=(2, 2))(P4_out)], filters, name="P5_out")
    P5_out = depthwise_separable_conv(P5_out, filters, kernel_size=3)

    P6_out = weighted_feature_fusion([P6, P6_td, MaxPooling2D(pool_size=(2, 2))(P5_out)], filters, name="P6_out")
    P6_out = depthwise_separable_conv(P6_out, filters, kernel_size=3)

    P7_out = weighted_feature_fusion([P7, MaxPooling2D(pool_size=(2, 2))(P6_out)], filters, name="P7_out")
    P7_out = depthwise_separable_conv(P7_out, filters, kernel_size=3)

    return [P3_td, P4_out, P5_out, P6_out, P7_out]


# Define the U-Net with BiFPN decoder
def unet_with_bifpn(input_size=(256, 256, 3)):
    inputs = Input(input_size)

    # Encoder
    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding="same")(inputs)
    conv1 = BatchNormalization()(conv1)
    conv1 = Activation("relu")(conv1)
    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding="same")(conv1)
    conv1 = BatchNormalization()(conv1)
    conv1 = Activation("relu")(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding="same")(pool1)
    conv2 = BatchNormalization()(conv2)
    conv2 = Activation("relu")(conv2)
    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding="same")(conv2)
    conv2 = BatchNormalization()(conv2)
    conv2 = Activation("relu")(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding="same")(pool2)
    conv3 = BatchNormalization()(conv3)
    conv3 = Activation("relu")(conv3)
    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding="same")(conv3)
    conv3 = BatchNormalization()(conv3)
    conv3 = Activation("relu")(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding="same")(pool3)
    conv4 = BatchNormalization()(conv4)
    conv4 = Activation("relu")(conv4)
    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding="same")(conv4)
    conv4 = BatchNormalization()(conv4)
    conv4 = Activation("relu")(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)

    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding="same")(pool4)
    conv5 = BatchNormalization()(conv5)
    conv5 = Activation("relu")(conv5)
    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding="same")(conv5)
    conv5 = BatchNormalization()(conv5)
    conv5 = Activation("relu")(conv5)

    # Decoder with BiFPN
    P3 = conv1
    P4 = conv2
    P5 = conv3
    P6 = conv4
    P7 = conv5

    # BiFPN
    features = [P3, P4, P5, P6, P7]
    bifpn_features = BiFPNBlock(features, filters=256)

    # Final segmentation head
    final_feature = bifpn_features[0]  # This can be adjusted based on which feature map is desired
    output = Conv2D(filters=1, kernel_size=(1, 1), activation="sigmoid")(final_feature)

    return Model(inputs=[inputs], outputs=[output])

# Create the model
model = unet_with_bifpn()

import tensorflow.keras.backend as K


def dice_coef(y_true, y_pred):
    y_true = tf.keras.layers.Flatten()(y_true)
    y_pred = tf.keras.layers.Flatten()(y_pred)
    intersection = tf.reduce_sum(y_true * y_pred)
    smooth = 1e-15
    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)

def iou(y_true, y_pred, num_classes=2):
    y_pred = K.round(y_pred)  #bc need binary values
    y_true = K.round(y_true)

    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred) - intersection

    return (intersection + 1) / (union + 1)


def pixel_accuracy(y_true, y_pred):
    y_pred = K.round(y_pred)
    y_true = K.round(y_true)
    return K.mean(K.equal(y_true, y_pred))

def dice_loss(y_true, y_pred):
    return 1.0 - dice_coef(y_true, y_pred)

from glob import glob
from skimage.io import imread
from skimage.transform import resize
from skimage.color import gray2rgb

H, W = 256, 256

def load_dataset(path):

    train_x = sorted(glob(f"{path}/images/train/*.jpg"))
    train_y = sorted(glob(f"{path}/annotations/train/*.png"))
    val_x = sorted(glob(f"{path}/images/val/*.jpg"))
    val_y = sorted(glob(f"{path}/annotations/val/*.png"))
    test_x = sorted(glob(f"{path}/images/test/*.jpg"))
    test_y = sorted(glob(f"{path}/annotations/test/*.png"))

    return (train_x, train_y), (val_x, val_y), (test_x, test_y)


def read_image(path):
    image = imread(path)
    image = resize(image, (H, W), preserve_range=True) / 255.0
    if len(image.shape) < 3:
        image = gray2rgb(image)
    elif len(image.shape) > 3:
        image = np.squeeze(image, axis=-2)
    return image


def read_mask(path):
    mask = imread(path)
    mask = resize(mask, (H, W), preserve_range=True)
    mask = (mask > 0).astype(np.float32)
    if len(mask.shape)==2:
        mask = np.expand_dims(mask, axis=-1)
    return mask


def get_batches(image_paths, mask_paths, batch_size):
    while True:
        for i in range(0, len(image_paths), batch_size):
            batch_images = [read_image(img) for img in image_paths[i:i+batch_size]]
            batch_masks = [read_mask(msk) for msk in mask_paths[i:i+batch_size]]

            yield np.array(batch_images), np.array(batch_masks)


def train_model(dataset_path):

    np.random.seed(42)
    tf.random.set_seed(42)

    (train_x, train_y), (valid_x, valid_y), _ = load_dataset(dataset_path)
    batch_size = 16

    model = unet_with_bifpn((256, 256, 3))
    # unet_with_bifpn(input_size=(256, 256, 3))
    model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss='binary_crossentropy',
    metrics = [dice_coef, iou, pixel_accuracy])

    model_path = '/kaggle/working/model.keras'
    csv_path = '/kaggle/working/training_log.csv'



    callbacks = [ModelCheckpoint(model_path, save_best_only=True, monitor="val_loss", verbose=1),
                 ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),
                 CSVLogger(csv_path),
                 TensorBoard(),
                 EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=False)]

    model.fit(
        get_batches(train_x, train_y, batch_size),
        steps_per_epoch = len(train_x) // batch_size,
        epochs = 3,
        validation_data = get_batches(valid_x, valid_y, batch_size),
        validation_steps = len(valid_x) // batch_size,
        callbacks = callbacks
    )

    return model_path

dataset_path = "/kaggle/input/plantseg/plantsegv2"
saved_model_path = train_model(dataset_path)